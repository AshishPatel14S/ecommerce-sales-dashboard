{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E-commerce Sales - Data Cleaning\n",
    "\n",
    "**Objective:** Clean and prepare the raw data for analysis.\n",
    "\n",
    "**Input:** Raw transaction data  \n",
    "**Output:** Cleaned dataset ready for analysis\n",
    "\n",
    "**Author:** [Your Name]  \n",
    "**Date:** [Date]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print('âœ… Libraries loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw data\n",
    "try:\n",
    "    df = pd.read_excel('../data/raw/online_retail_II.xlsx', sheet_name='Year 2010-2011')\n",
    "    print(f'âœ… Loaded full dataset: {len(df):,} rows')\n",
    "except FileNotFoundError:\n",
    "    df = pd.read_csv('../data/sample/sample_data.csv')\n",
    "    print(f'âš ï¸ Using sample data: {len(df):,} rows')\n",
    "\n",
    "original_rows = len(df)\n",
    "print(f'\\nStarting with {original_rows:,} rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Standardize Column Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize column names\n",
    "print('ðŸ“‹ Standardizing column names...')\n",
    "print(f'   Before: {list(df.columns)}')\n",
    "\n",
    "# Rename for consistency\n",
    "df.columns = df.columns.str.strip().str.replace(' ', '_')\n",
    "\n",
    "# Common renames\n",
    "rename_map = {\n",
    "    'Customer_ID': 'Customer ID',\n",
    "    'CustomerID': 'Customer ID',\n",
    "    'InvoiceNo': 'Invoice',\n",
    "    'UnitPrice': 'Price'\n",
    "}\n",
    "df = df.rename(columns={k: v for k, v in rename_map.items() if k in df.columns})\n",
    "\n",
    "print(f'   After: {list(df.columns)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ðŸ”§ Handling missing values...')\n",
    "\n",
    "# Check missing\n",
    "missing_before = df.isnull().sum()\n",
    "print(f'\\n   Missing values before:')\n",
    "print(missing_before[missing_before > 0])\n",
    "\n",
    "# Customer ID: Keep rows with missing (guest checkouts) but flag them\n",
    "df['IsGuest'] = df['Customer ID'].isnull().astype(int)\n",
    "print(f'\\n   Guest checkouts flagged: {df[\"IsGuest\"].sum():,}')\n",
    "\n",
    "# Description: Fill with 'Unknown' or drop\n",
    "if 'Description' in df.columns:\n",
    "    df['Description'] = df['Description'].fillna('Unknown')\n",
    "\n",
    "print('\\n   âœ… Missing values handled')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Remove Cancellations and Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ðŸ”§ Removing cancellations and returns...')\n",
    "\n",
    "# Flag cancellations (Invoice starts with 'C')\n",
    "df['IsCancellation'] = df['Invoice'].astype(str).str.startswith('C')\n",
    "cancellations = df['IsCancellation'].sum()\n",
    "print(f'   Cancellations found: {cancellations:,}')\n",
    "\n",
    "# Remove cancellations for analysis\n",
    "df_clean = df[~df['IsCancellation']].copy()\n",
    "print(f'   Rows after removing cancellations: {len(df_clean):,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Handle Invalid Quantities and Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ðŸ”§ Handling invalid quantities and prices...')\n",
    "\n",
    "# Remove negative quantities (returns already removed with cancellations)\n",
    "neg_qty = (df_clean['Quantity'] <= 0).sum()\n",
    "print(f'   Negative/zero quantities: {neg_qty:,}')\n",
    "df_clean = df_clean[df_clean['Quantity'] > 0]\n",
    "\n",
    "# Remove zero/negative prices\n",
    "invalid_price = (df_clean['Price'] <= 0).sum()\n",
    "print(f'   Invalid prices: {invalid_price:,}')\n",
    "df_clean = df_clean[df_clean['Price'] > 0]\n",
    "\n",
    "print(f'   Rows remaining: {len(df_clean):,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Remove Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ðŸ”§ Handling outliers...')\n",
    "\n",
    "# Calculate revenue\n",
    "df_clean['Revenue'] = df_clean['Quantity'] * df_clean['Price']\n",
    "\n",
    "# Remove extreme outliers (>99.9th percentile)\n",
    "qty_threshold = df_clean['Quantity'].quantile(0.999)\n",
    "price_threshold = df_clean['Price'].quantile(0.999)\n",
    "revenue_threshold = df_clean['Revenue'].quantile(0.999)\n",
    "\n",
    "print(f'   Quantity 99.9th percentile: {qty_threshold:.0f}')\n",
    "print(f'   Price 99.9th percentile: Â£{price_threshold:.2f}')\n",
    "print(f'   Revenue 99.9th percentile: Â£{revenue_threshold:.2f}')\n",
    "\n",
    "# Filter extreme outliers\n",
    "before_outliers = len(df_clean)\n",
    "df_clean = df_clean[\n",
    "    (df_clean['Quantity'] <= qty_threshold) &\n",
    "    (df_clean['Price'] <= price_threshold) &\n",
    "    (df_clean['Revenue'] <= revenue_threshold)\n",
    "]\n",
    "outliers_removed = before_outliers - len(df_clean)\n",
    "print(f'   Outliers removed: {outliers_removed:,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Add Derived Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ðŸ”§ Adding derived features...')\n",
    "\n",
    "# Ensure datetime\n",
    "df_clean['InvoiceDate'] = pd.to_datetime(df_clean['InvoiceDate'])\n",
    "\n",
    "# Date features\n",
    "df_clean['Year'] = df_clean['InvoiceDate'].dt.year\n",
    "df_clean['Month'] = df_clean['InvoiceDate'].dt.month\n",
    "df_clean['DayOfWeek'] = df_clean['InvoiceDate'].dt.dayofweek\n",
    "df_clean['Hour'] = df_clean['InvoiceDate'].dt.hour\n",
    "df_clean['IsWeekend'] = df_clean['DayOfWeek'].isin([5, 6]).astype(int)\n",
    "\n",
    "print('   Added: Year, Month, DayOfWeek, Hour, IsWeekend')\n",
    "\n",
    "# Revenue already calculated above\n",
    "print('   Added: Revenue (Quantity Ã— Price)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Validate Final Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('âœ… Validation Checks')\n",
    "print('=' * 50)\n",
    "\n",
    "# No missing values in key columns\n",
    "key_cols = ['Invoice', 'StockCode', 'Quantity', 'Price', 'InvoiceDate', 'Country', 'Revenue']\n",
    "missing_key = df_clean[key_cols].isnull().sum().sum()\n",
    "print(f'Missing in key columns: {missing_key} âœ…' if missing_key == 0 else f'Missing in key columns: {missing_key} âŒ')\n",
    "\n",
    "# All quantities positive\n",
    "neg_qty = (df_clean['Quantity'] <= 0).sum()\n",
    "print(f'Negative quantities: {neg_qty} âœ…' if neg_qty == 0 else f'Negative quantities: {neg_qty} âŒ')\n",
    "\n",
    "# All prices positive\n",
    "neg_price = (df_clean['Price'] <= 0).sum()\n",
    "print(f'Negative prices: {neg_price} âœ…' if neg_price == 0 else f'Negative prices: {neg_price} âŒ')\n",
    "\n",
    "# All revenues positive\n",
    "neg_rev = (df_clean['Revenue'] <= 0).sum()\n",
    "print(f'Negative revenue: {neg_rev} âœ…' if neg_rev == 0 else f'Negative revenue: {neg_rev} âŒ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ðŸ’¾ Saving cleaned data...')\n",
    "\n",
    "# Create output directory\n",
    "output_dir = Path('../data/processed')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save\n",
    "df_clean.to_csv(output_dir / 'cleaned_transactions.csv', index=False)\n",
    "print(f'   Saved to: {output_dir}/cleaned_transactions.csv')\n",
    "print(f'   Final rows: {len(df_clean):,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Cleaning Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=' * 60)\n",
    "print('ðŸ“Š CLEANING SUMMARY')\n",
    "print('=' * 60)\n",
    "\n",
    "rows_removed = original_rows - len(df_clean)\n",
    "pct_removed = rows_removed / original_rows * 100\n",
    "\n",
    "print(f\"\"\"\n",
    "ROWS:\n",
    "â€¢ Original: {original_rows:,}\n",
    "â€¢ Final: {len(df_clean):,}\n",
    "â€¢ Removed: {rows_removed:,} ({pct_removed:.1f}%)\n",
    "\n",
    "CLEANING STEPS:\n",
    "1. Standardized column names\n",
    "2. Flagged guest checkouts (missing Customer ID)\n",
    "3. Removed cancellations (Invoice starting with 'C')\n",
    "4. Removed negative/zero quantities\n",
    "5. Removed invalid prices (â‰¤0)\n",
    "6. Removed extreme outliers (>99.9th percentile)\n",
    "7. Added derived features (Year, Month, DayOfWeek, Hour, Revenue)\n",
    "\n",
    "FINAL DATASET:\n",
    "â€¢ Transactions: {len(df_clean):,}\n",
    "â€¢ Customers: {df_clean['Customer ID'].nunique():,}\n",
    "â€¢ Products: {df_clean['StockCode'].nunique():,}\n",
    "â€¢ Countries: {df_clean['Country'].nunique()}\n",
    "â€¢ Total Revenue: Â£{df_clean['Revenue'].sum():,.2f}\n",
    "\n",
    "âœ… Ready for analysis in 03_analysis.ipynb\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
